{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2c1e6a-6088-4c1f-8f94-53cf11ba134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "29/29 [==============================] - 2s 36ms/step - loss: 0.3855 - accuracy: 0.8382 - val_loss: 0.3107 - val_accuracy: 0.8785\n",
      "Epoch 2/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.2733 - accuracy: 0.8848 - val_loss: 0.2664 - val_accuracy: 0.8901\n",
      "Epoch 3/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.2270 - accuracy: 0.9080 - val_loss: 0.2358 - val_accuracy: 0.8983\n",
      "Epoch 4/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.2093 - accuracy: 0.9165 - val_loss: 0.2142 - val_accuracy: 0.9017\n",
      "Epoch 5/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.2089 - accuracy: 0.9154 - val_loss: 0.3249 - val_accuracy: 0.8570\n",
      "Epoch 6/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.1769 - accuracy: 0.9286 - val_loss: 0.1877 - val_accuracy: 0.9289\n",
      "Epoch 7/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1724 - accuracy: 0.9344 - val_loss: 0.1652 - val_accuracy: 0.9314\n",
      "Epoch 8/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1589 - accuracy: 0.9369 - val_loss: 0.1166 - val_accuracy: 0.9686\n",
      "Epoch 9/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1471 - accuracy: 0.9416 - val_loss: 0.2530 - val_accuracy: 0.8810\n",
      "Epoch 10/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1394 - accuracy: 0.9471 - val_loss: 0.1085 - val_accuracy: 0.9562\n",
      "Epoch 11/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9540 - val_loss: 0.1112 - val_accuracy: 0.9653\n",
      "Epoch 12/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1512 - accuracy: 0.9427 - val_loss: 0.1329 - val_accuracy: 0.9463\n",
      "Epoch 13/150\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1207 - accuracy: 0.9532 - val_loss: 0.2119 - val_accuracy: 0.9157\n",
      "Epoch 14/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1143 - accuracy: 0.9548 - val_loss: 0.0858 - val_accuracy: 0.9736\n",
      "Epoch 15/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1232 - accuracy: 0.9512 - val_loss: 0.1052 - val_accuracy: 0.9579\n",
      "Epoch 16/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1370 - accuracy: 0.9452 - val_loss: 0.0851 - val_accuracy: 0.9678\n",
      "Epoch 17/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1029 - accuracy: 0.9606 - val_loss: 0.2589 - val_accuracy: 0.9091\n",
      "Epoch 18/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1328 - accuracy: 0.9523 - val_loss: 0.0688 - val_accuracy: 0.9769\n",
      "Epoch 19/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.9650 - val_loss: 0.1092 - val_accuracy: 0.9628\n",
      "Epoch 20/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1090 - accuracy: 0.9634 - val_loss: 0.3160 - val_accuracy: 0.8950\n",
      "Epoch 21/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 0.9567 - val_loss: 0.1079 - val_accuracy: 0.9603\n",
      "Epoch 22/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1058 - accuracy: 0.9595 - val_loss: 0.0946 - val_accuracy: 0.9603\n",
      "Epoch 23/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.1029 - accuracy: 0.9639 - val_loss: 0.2058 - val_accuracy: 0.9198\n",
      "Epoch 24/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1012 - accuracy: 0.9634 - val_loss: 0.1272 - val_accuracy: 0.9446\n",
      "Epoch 25/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0953 - accuracy: 0.9636 - val_loss: 0.1511 - val_accuracy: 0.9314\n",
      "Epoch 26/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9658 - val_loss: 0.0605 - val_accuracy: 0.9793\n",
      "Epoch 27/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0948 - accuracy: 0.9628 - val_loss: 0.0936 - val_accuracy: 0.9603\n",
      "Epoch 28/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0994 - accuracy: 0.9650 - val_loss: 0.0528 - val_accuracy: 0.9818\n",
      "Epoch 29/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.1112 - val_accuracy: 0.9496\n",
      "Epoch 30/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0773 - accuracy: 0.9678 - val_loss: 0.1631 - val_accuracy: 0.9388\n",
      "Epoch 31/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0924 - accuracy: 0.9622 - val_loss: 0.1436 - val_accuracy: 0.9471\n",
      "Epoch 32/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0843 - accuracy: 0.9686 - val_loss: 0.0656 - val_accuracy: 0.9736\n",
      "Epoch 33/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0851 - accuracy: 0.9678 - val_loss: 0.0969 - val_accuracy: 0.9595\n",
      "Epoch 34/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0908 - accuracy: 0.9672 - val_loss: 0.0551 - val_accuracy: 0.9752\n",
      "Epoch 35/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9702 - val_loss: 0.0509 - val_accuracy: 0.9843\n",
      "Epoch 36/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.9722 - val_loss: 0.0554 - val_accuracy: 0.9802\n",
      "Epoch 37/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0966 - accuracy: 0.9658 - val_loss: 0.0434 - val_accuracy: 0.9901\n",
      "Epoch 38/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9724 - val_loss: 0.0556 - val_accuracy: 0.9752\n",
      "Epoch 39/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0793 - accuracy: 0.9691 - val_loss: 0.1143 - val_accuracy: 0.9488\n",
      "Epoch 40/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 0.0442 - val_accuracy: 0.9868\n",
      "Epoch 41/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0774 - accuracy: 0.9708 - val_loss: 0.0387 - val_accuracy: 0.9909\n",
      "Epoch 42/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0854 - accuracy: 0.9694 - val_loss: 0.0517 - val_accuracy: 0.9802\n",
      "Epoch 43/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0768 - accuracy: 0.9702 - val_loss: 0.0909 - val_accuracy: 0.9711\n",
      "Epoch 44/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0755 - accuracy: 0.9686 - val_loss: 0.0892 - val_accuracy: 0.9653\n",
      "Epoch 45/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.0474 - val_accuracy: 0.9818\n",
      "Epoch 46/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0753 - accuracy: 0.9730 - val_loss: 0.0547 - val_accuracy: 0.9785\n",
      "Epoch 47/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9683 - val_loss: 0.0527 - val_accuracy: 0.9802\n",
      "Epoch 48/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0871 - accuracy: 0.9656 - val_loss: 0.2083 - val_accuracy: 0.9405\n",
      "Epoch 49/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9705 - val_loss: 0.0385 - val_accuracy: 0.9901\n",
      "Epoch 50/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0681 - accuracy: 0.9730 - val_loss: 0.0438 - val_accuracy: 0.9851\n",
      "Epoch 51/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0791 - accuracy: 0.9683 - val_loss: 0.0570 - val_accuracy: 0.9727\n",
      "Epoch 52/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 0.0393 - val_accuracy: 0.9818\n",
      "Epoch 53/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0731 - accuracy: 0.9733 - val_loss: 0.0992 - val_accuracy: 0.9579\n",
      "Epoch 54/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9691 - val_loss: 0.0391 - val_accuracy: 0.9876\n",
      "Epoch 55/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.0424 - val_accuracy: 0.9851\n",
      "Epoch 56/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0841 - accuracy: 0.9733 - val_loss: 0.0403 - val_accuracy: 0.9876\n",
      "Epoch 57/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0752 - accuracy: 0.9708 - val_loss: 0.0400 - val_accuracy: 0.9876\n",
      "Epoch 58/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0794 - accuracy: 0.9735 - val_loss: 0.1064 - val_accuracy: 0.9603\n",
      "Epoch 59/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9702 - val_loss: 0.0571 - val_accuracy: 0.9744\n",
      "Epoch 60/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0780 - accuracy: 0.9724 - val_loss: 0.0941 - val_accuracy: 0.9628\n",
      "Epoch 61/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9733 - val_loss: 0.0409 - val_accuracy: 0.9876\n",
      "Epoch 62/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0709 - accuracy: 0.9738 - val_loss: 0.0867 - val_accuracy: 0.9636\n",
      "Epoch 63/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.9730 - val_loss: 0.0469 - val_accuracy: 0.9810\n",
      "Epoch 64/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0691 - accuracy: 0.9791 - val_loss: 0.0883 - val_accuracy: 0.9603\n",
      "Epoch 65/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9752 - val_loss: 0.0376 - val_accuracy: 0.9884\n",
      "Epoch 66/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 0.0552 - val_accuracy: 0.9777\n",
      "Epoch 67/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.0513 - val_accuracy: 0.9777\n",
      "Epoch 68/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0681 - accuracy: 0.9744 - val_loss: 0.0515 - val_accuracy: 0.9785\n",
      "Epoch 69/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 0.9791 - val_loss: 0.0717 - val_accuracy: 0.9661\n",
      "Epoch 70/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9741 - val_loss: 0.0781 - val_accuracy: 0.9653\n",
      "Epoch 71/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9708 - val_loss: 0.0677 - val_accuracy: 0.9702\n",
      "Epoch 72/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0666 - accuracy: 0.9724 - val_loss: 0.0727 - val_accuracy: 0.9744\n",
      "Epoch 73/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.9741 - val_loss: 0.0300 - val_accuracy: 0.9926\n",
      "Epoch 74/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.0409 - val_accuracy: 0.9868\n",
      "Epoch 75/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 0.9675 - val_loss: 0.0636 - val_accuracy: 0.9752\n",
      "Epoch 76/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0783 - accuracy: 0.9730 - val_loss: 0.0560 - val_accuracy: 0.9835\n",
      "Epoch 77/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0655 - val_accuracy: 0.9736\n",
      "Epoch 78/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0629 - accuracy: 0.9791 - val_loss: 0.0393 - val_accuracy: 0.9876\n",
      "Epoch 79/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 0.0312 - val_accuracy: 0.9884\n",
      "Epoch 80/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.0639 - val_accuracy: 0.9802\n",
      "Epoch 81/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0589 - accuracy: 0.9788 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
      "Epoch 82/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0655 - accuracy: 0.9777 - val_loss: 0.0642 - val_accuracy: 0.9694\n",
      "Epoch 83/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0652 - accuracy: 0.9763 - val_loss: 0.0748 - val_accuracy: 0.9636\n",
      "Epoch 84/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0345 - val_accuracy: 0.9860\n",
      "Epoch 85/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0597 - accuracy: 0.9791 - val_loss: 0.0472 - val_accuracy: 0.9826\n",
      "Epoch 86/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.0629 - val_accuracy: 0.9736\n",
      "Epoch 87/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.9746 - val_loss: 0.0259 - val_accuracy: 0.9901\n",
      "Epoch 88/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0596 - accuracy: 0.9782 - val_loss: 0.0337 - val_accuracy: 0.9860\n",
      "Epoch 89/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.0685 - val_accuracy: 0.9678\n",
      "Epoch 90/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0691 - accuracy: 0.9758 - val_loss: 0.0552 - val_accuracy: 0.9802\n",
      "Epoch 91/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 0.0663 - val_accuracy: 0.9645\n",
      "Epoch 92/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0529 - accuracy: 0.9813 - val_loss: 0.0310 - val_accuracy: 0.9926\n",
      "Epoch 93/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0624 - accuracy: 0.9780 - val_loss: 0.0486 - val_accuracy: 0.9818\n",
      "Epoch 94/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.0303 - val_accuracy: 0.9893\n",
      "Epoch 95/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0716 - accuracy: 0.9719 - val_loss: 0.0313 - val_accuracy: 0.9917\n",
      "Epoch 96/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9807 - val_loss: 0.0692 - val_accuracy: 0.9702\n",
      "Epoch 97/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0676 - accuracy: 0.9744 - val_loss: 0.1040 - val_accuracy: 0.9554\n",
      "Epoch 98/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9771 - val_loss: 0.0767 - val_accuracy: 0.9694\n",
      "Epoch 99/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0717 - accuracy: 0.9744 - val_loss: 0.1598 - val_accuracy: 0.9438\n",
      "Epoch 100/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.0631 - val_accuracy: 0.9760\n",
      "Epoch 101/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0571 - accuracy: 0.9785 - val_loss: 0.0248 - val_accuracy: 0.9934\n",
      "Epoch 102/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0616 - accuracy: 0.9769 - val_loss: 0.1315 - val_accuracy: 0.9529\n",
      "Epoch 103/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 0.0278 - val_accuracy: 0.9926\n",
      "Epoch 104/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0421 - val_accuracy: 0.9826\n",
      "Epoch 105/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0555 - accuracy: 0.9788 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 106/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0763 - accuracy: 0.9700 - val_loss: 0.0823 - val_accuracy: 0.9653\n",
      "Epoch 107/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.0263 - val_accuracy: 0.9917\n",
      "Epoch 108/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.0830 - val_accuracy: 0.9653\n",
      "Epoch 109/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 0.0409 - val_accuracy: 0.9843\n",
      "Epoch 110/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.0239 - val_accuracy: 0.9909\n",
      "Epoch 111/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.1031 - val_accuracy: 0.9661\n",
      "Epoch 112/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0503 - accuracy: 0.9804 - val_loss: 0.0405 - val_accuracy: 0.9868\n",
      "Epoch 113/150\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.9771 - val_loss: 0.0204 - val_accuracy: 0.9959\n",
      "Epoch 114/150\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9802 - val_loss: 0.0414 - val_accuracy: 0.9818\n",
      "Epoch 115/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.9788 - val_loss: 0.0320 - val_accuracy: 0.9876\n",
      "Epoch 116/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9832 - val_loss: 0.0327 - val_accuracy: 0.9901\n",
      "Epoch 117/150\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.1792 - val_accuracy: 0.9446\n",
      "Epoch 118/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0671 - accuracy: 0.9755 - val_loss: 0.0234 - val_accuracy: 0.9959\n",
      "Epoch 119/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0701 - accuracy: 0.9755 - val_loss: 0.0548 - val_accuracy: 0.9752\n",
      "Epoch 120/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 0.0415 - val_accuracy: 0.9893\n",
      "Epoch 121/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0613 - accuracy: 0.9771 - val_loss: 0.0206 - val_accuracy: 0.9934\n",
      "Epoch 122/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.0277 - val_accuracy: 0.9893\n",
      "Epoch 123/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0673 - accuracy: 0.9807 - val_loss: 0.0468 - val_accuracy: 0.9802\n",
      "Epoch 124/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9810 - val_loss: 0.0264 - val_accuracy: 0.9917\n",
      "Epoch 125/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0543 - accuracy: 0.9804 - val_loss: 0.0269 - val_accuracy: 0.9884\n",
      "Epoch 126/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 0.9802 - val_loss: 0.0799 - val_accuracy: 0.9694\n",
      "Epoch 127/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9802 - val_loss: 0.0813 - val_accuracy: 0.9620\n",
      "Epoch 128/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.9793 - val_loss: 0.0481 - val_accuracy: 0.9851\n",
      "Epoch 129/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0508 - accuracy: 0.9810 - val_loss: 0.0484 - val_accuracy: 0.9843\n",
      "Epoch 130/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.0253 - val_accuracy: 0.9901\n",
      "Epoch 131/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0493 - accuracy: 0.9826 - val_loss: 0.0245 - val_accuracy: 0.9950\n",
      "Epoch 132/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.0181 - val_accuracy: 0.9942\n",
      "Epoch 133/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.0556 - val_accuracy: 0.9793\n",
      "Epoch 134/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9843 - val_loss: 0.0462 - val_accuracy: 0.9826\n",
      "Epoch 135/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0592 - val_accuracy: 0.9686\n",
      "Epoch 136/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0511 - accuracy: 0.9810 - val_loss: 0.0338 - val_accuracy: 0.9909\n",
      "Epoch 137/150\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.0451 - val_accuracy: 0.9826\n",
      "Epoch 138/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0661 - accuracy: 0.9752 - val_loss: 0.0453 - val_accuracy: 0.9851\n",
      "Epoch 139/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 0.0319 - val_accuracy: 0.9884\n",
      "Epoch 140/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0456 - accuracy: 0.9826 - val_loss: 0.0308 - val_accuracy: 0.9901\n",
      "Epoch 141/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 0.1373 - val_accuracy: 0.9570\n",
      "Epoch 142/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0642 - accuracy: 0.9771 - val_loss: 0.0349 - val_accuracy: 0.9876\n",
      "Epoch 143/150\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.0544 - val_accuracy: 0.9843\n",
      "Epoch 144/150\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9749 - val_loss: 0.0430 - val_accuracy: 0.9876\n",
      "Epoch 145/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.0269 - val_accuracy: 0.9934\n",
      "Epoch 146/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0463 - accuracy: 0.9843 - val_loss: 0.0244 - val_accuracy: 0.9917\n",
      "Epoch 147/150\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0495 - accuracy: 0.9826 - val_loss: 0.0910 - val_accuracy: 0.9678\n",
      "Epoch 148/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.0339 - val_accuracy: 0.9868\n",
      "Epoch 149/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.9796 - val_loss: 0.0214 - val_accuracy: 0.9909\n",
      "Epoch 150/150\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0211 - val_accuracy: 0.9909\n",
      "Training Time for Neural Network with Attention: 56.01 seconds\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Training Time for HistGradientBoosting with Grid Search: 121.28 seconds\n",
      "Training Time for Stacking Model: 13.71 seconds\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Testing Time for Hybrid Model with Attention: 0.71 seconds\n",
      "Hybrid Model with Attention Accuracy: 0.9967\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0   1.000000  0.992629  0.996301       407\n",
      "         2.0   0.992611  1.000000  0.996292       403\n",
      "         3.0   0.997500  0.997500  0.997500       400\n",
      "\n",
      "    accuracy                       0.996694      1210\n",
      "   macro avg   0.996704  0.996710  0.996698      1210\n",
      "weighted avg   0.996713  0.996694  0.996694      1210\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[404   2   1]\n",
      " [  0 403   0]\n",
      " [  0   1 399]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Compute evaluation metrics\u001b[39;00m\n\u001b[0;32m    143\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, final_preds_with_attention)\n\u001b[1;32m--> 144\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m(y_test, final_preds_with_attention, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, final_preds_with_attention, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    146\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, final_preds_with_attention, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # Required to use HistGradientBoosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Dropout, Reshape, Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Load Dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\abdul\\Desktop\\research work\\fetal_health.csv\")  # Replace with the actual path\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['fetal_health'] = label_encoder.fit_transform(data['fetal_health'])\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('fetal_health', axis=1)\n",
    "y = data['fetal_health']\n",
    "\n",
    "# Handle Imbalanced Dataset\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, stratify=y_resampled, random_state=42)\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight',\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(1,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)  # Calculate attention scores\n",
    "        a = K.softmax(e, axis=1)              # Apply softmax to get attention weights\n",
    "        output = x * a                        # Apply weights to input\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "# Neural Network with Attention (Using RMSprop Optimizer)\n",
    "def build_nn_with_attention(input_dim, learning_rate=0.01, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Reshape((1, 128)),  # Reshape to (batch_size, timesteps, features) for Attention\n",
    "        Attention(),\n",
    "\n",
    "        Dense(3, activation='softmax')  # Output Layer\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Measure Training Time for Neural Network with Attention\n",
    "start_time_nn = time.time()\n",
    "nn_model_with_attention = build_nn_with_attention(X_train_scaled.shape[1], learning_rate=0.01, dropout_rate=0.3)\n",
    "nn_model_with_attention.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=150, batch_size=128, verbose=1)\n",
    "end_time_nn = time.time()\n",
    "nn_training_time = end_time_nn - start_time_nn\n",
    "print(f\"Training Time for Neural Network with Attention: {nn_training_time:.2f} seconds\")\n",
    "\n",
    "# Hyperparameter Tuning for HistGradientBoostingClassifier\n",
    "hgb_param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'min_samples_leaf': [20, 30, 40],\n",
    "}\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Measure Training Time for HistGradientBoosting\n",
    "start_time_hgb = time.time()\n",
    "grid_search_hgb = GridSearchCV(hgb, hgb_param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search_hgb.fit(X_train_scaled, y_train)\n",
    "end_time_hgb = time.time()\n",
    "hgb_training_time = end_time_hgb - start_time_hgb\n",
    "print(f\"Training Time for HistGradientBoosting with Grid Search: {hgb_training_time:.2f} seconds\")\n",
    "\n",
    "# Stacking Ensemble\n",
    "start_time_stack = time.time()\n",
    "hgb_best = grid_search_hgb.best_estimator_\n",
    "estimators = [('hgb', hgb_best)]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "end_time_stack = time.time()\n",
    "stacking_training_time = end_time_stack - start_time_stack\n",
    "print(f\"Training Time for Stacking Model: {stacking_training_time:.2f} seconds\")\n",
    "\n",
    "# Measure Testing Time for Hybrid Model\n",
    "start_time_test = time.time()\n",
    "stacking_probs = stacking_model.predict_proba(X_test_scaled)\n",
    "nn_probs_with_attention = nn_model_with_attention.predict(X_test_scaled)\n",
    "final_probs_with_attention = (stacking_probs + nn_probs_with_attention) / 2\n",
    "final_preds_with_attention = np.argmax(final_probs_with_attention, axis=1)\n",
    "end_time_test = time.time()\n",
    "testing_time = end_time_test - start_time_test\n",
    "print(f\"Testing Time for Hybrid Model with Attention: {testing_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate Hybrid Model with Attention\n",
    "accuracy_with_attention = accuracy_score(y_test, final_preds_with_attention)\n",
    "print(f\"Hybrid Model with Attention Accuracy: {accuracy_with_attention:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "target_names = [str(cls) for cls in label_encoder.classes_]\n",
    "print(classification_report(y_test, final_preds_with_attention, target_names=target_names, digits=6))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, final_preds_with_attention))\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, final_preds_with_attention)\n",
    "precision = precision_score(y_test, final_preds_with_attention, average=\"macro\")\n",
    "recall = recall_score(y_test, final_preds_with_attention, average=\"macro\")\n",
    "f1 = f1_score(y_test, final_preds_with_attention, average=\"macro\")\n",
    "\n",
    "print(f\"\\nHybrid Model Accuracy: {accuracy:.6f}\")\n",
    "print(f\"Macro Precision: {precision:.6f}\")\n",
    "print(f\"Macro Recall: {recall:.6f}\")\n",
    "print(f\"Macro F1-score: {f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd8608-7f52-488e-81ac-08faae0be501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
